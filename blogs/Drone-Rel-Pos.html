<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <title>Matthew Bird</title>
    <meta name="description" content="Matthew Bird Portfolio">
    <meta name="keywords" content="Matthew Bird, About, Portfolio">
    
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <link rel="stylesheet" href="/main.css">
    <link rel="stylesheet" href="/blog.css">
</head>
<body>
    <!-- Navbar -->
    <nav class="navbar navbar-expand-sm sticky-top navbar-light" id="navbar">
    <div class="container-fluid">
        <a href="/" class="navbar-brand">Matthew Bird</a>
        
        <!-- links -->
        <div class="collapse navbar-collapse">
        <ul class="navbar-nav ms-auto" id="navbar-links">
            <li class="nav-item">
                <a id="home-nav" href="/" class="nav-link theme2">Home</a>
            </li>
            
            <li class="nav-item">
                <a id="blogs-nav" href="/blogs.html" class="nav-link theme2">Blogs</a>
            </li>

            <li class="nav-item">
                <a id="about-nav" href="/about.html" class="nav-link theme2">About</a>
            </li>
        </ul>
        </div>
    </div>
    </nav>


    <!-- Content -->
    <div class="content col-md-8 offset-md-2 col-12">
        <div class="header">
            <h1 class="title d-inline">Drone Relative Positioning</h1>
            <h6 class="tags d-inline">[Drones]</h6>
            <h6 class="tags d-inline">[Computer Vision]</h6>
            <h3 class="synopsis">Basic localization with cameras using feature matching and mapping</h3>
            <h6 class="author d-inline">Matthew Bird</h6>
            <h6 class="date d-inline">Thu, Oct 10, 2024</h6>
        </div>
        <div class="main">
            <div class="embed-responsive embed-responsive-16by9">
                <iframe class="embed-responsive-item d-inline" src="" allowfullscreen></iframe>
            </div>
            <h4>Demo Vids: <a href=""></a>
            <h4>Github Repository: <a href="https://github.com/mbird1258/Drone-relative-positioning">https://github.com/mbird1258/Drone-relative-positioning</a></h4>
            
            <h2>Premise</h2>
            <p>My plan for this project was to determine the relative positioning and orientation of two or more objects with cameras using minimal usage of external libraries. I was inspired to do this by drone shows in HK. </p>

            <h2>How it works</h2>
            <h3>Overview</h3>
            <p>The code uses two cameras on the central drone to create a 3d map of features, then the other drones can do the reverse from any two points to determine its own position in this 3d map of points. </p>

            <h3>Feature detection</h3>
            <p>To detect features, we use the <a href="https://en.m.wikipedia.org/wiki/Features_from_accelerated_segment_test">FAST algorithm</a> to detect corners. Then, we calculate descriptors for each of these points that are scale and rotationally invariant and match the points to each other.</p>
            <img src="..\assets\imgs\Drone Rel Pos\1.jpg">
            
            <h3>Feature triangulation</h3>
            <p>To find the 3d position of the features, we can draw a line in 3d space from the center of both cameras on the central drone and approximate the intersecting point in 3d space to find the feature’s position in 3d space. </p>
            <img src="..\assets\imgs\Drone Rel Pos\2.jpg">
            
            <h3>Reverse triangulation</h3>
            <p>To find the 3d position of a camera from any two features, we can use the same method as before, but instead of drawing from the center of both cameras, we anchor the lines on the feature points in 3d space and approximate the intersection to find our camera’s position. We do this for every set of two features and remove outliers to get our final position. </p>
            
            <h3>Accounting for orientation</h3>
            <p>To account for the orientation, we first need to find our orientation. For pitch and roll, I used an accelerometer, but finding yaw is a bit more difficult.</p>
            <p>To find the yaw, we take any pair of matched features across two cameras, one from the central drone and another from the second drone. Then, we can use the offset in angle of the descriptors we used, such as the difference in direction of the vectors from the same descriptor, which we calculated during feature matching. This gives us the relative yaw of every drone with respect to the central drone.</p>
            <img src="..\assets\imgs\Drone Rel Pos\3.jpg">
            <p>Accounting for yaw is not too hard, as we can rotate the images we captured from the cameras by the corresponding yaw angle before triangulating the points. </p>
            <img src="..\assets\imgs\Drone Rel Pos\4.jpg">
            <p>To account for pitch and roll on the central drone, after triangulating the 3d position of all the features, we can then rotate their positions around the origin in accordance with the pitch and yaw to properly account for the pitch and roll. </p>
            <img src="..\assets\imgs\Drone Rel Pos\5.jpg">
            <p>For the secondary drones, we can change the stored position of the features on the screen in accordance with the pitch and roll before triangulating the position of the camera. This effectively changes the slope of all the lines before determining their intersection point to properly account for the pitch and roll. </p>
            <img src="..\assets\imgs\Drone Rel Pos\6.jpg">
            
            <h3>Hardware</h3>
            <p>The full list of hardware used in this project are 3 RasPi 0Ws, 3 RasPi camera modules, 2 accelerometers, 2 power banks, 3 usb to micro usb cables, 3 micro SD cards, and a micro SD to usb adapter. </p>
            <p class="multiline">Full list:
        - <a href="https://www.aliexpress.com/item/1005005792181612.html?spm=a2g0o.order_list.order_list_main.30.60651802iXxuYL">RasPi 0W</a>
        - <a href="https://www.aliexpress.com/item/32901067278.html?spm=a2g0o.order_list.order_list_main.25.60651802iXxuYL">RasPi camera module</a>
        - <a href="https://www.aliexpress.com/item/32452794842.html?spm=a2g0o.order_list.order_list_main.20.60651802iXxuYL">ADXL345 Accelerometer</a>
        - <a href="https://www.aliexpress.com/item/32974708727.html?spm=a2g0o.order_list.order_list_main.10.60651802iXxuYL">Power Bank</a>
        - <a href="https://www.aliexpress.com/item/32391749504.html?spm=a2g0o.order_list.order_list_main.15.60651802iXxuYL">MicroUSB Cable</a>
        - <a href="https://www.amazon.com/SanDisk-2-Pack-microSDHC-Memory-2x32GB/dp/B08GY9NYRM/ref=sr_1_3?crid=1O6LZJGU106Q9&dib=eyJ2IjoiMSJ9.tk0UAe6rKAf0FakbuJisoKUomV5T1j37HI71I94y2M_0QZwoxj-Tbw4sowKCr5WH9cyxWaNy7Mp6M_TIFeIaR_qOvvHAY7o7dNKHDUPhbLF3upGURhtAnm_L4jIt9CVhJRwHXjG2nIccV6KGlFkV8OSFyigdYplNKJ5PTfbVfDw2Fj8cdMeZttrEGsuu9y9oyI03ARWcVrcQE0bjQ0P35HTuzZoyZXaxSIMG2Q2Lq6c.5OWHbjcGPRzyfdBfUICGkGpP_jsD--OYMbEoxqXcZuc&dib_tag=se&keywords=32%2Bgb%2Bmicro%2Bsd%2Bcard&qid=1721202707&sprefix=32%2Bgb%2Bmicro%2Bsd%2Bca%2Caps%2C342&sr=8-3&th=1">MicroSD</a>
        - <a href="https://www.aliexpress.com/item/1005005492821617.html?spm=a2g0o.order_list.order_list_main.5.60651802iXxuYL">MicroSD Reader</a></p>
            <p>The Raspberry Pis are used with Socket to connect to the computer and send over the camera and accelerometer data. (<a href="https://docs.google.com/document/d/1zvPyD8OOzXOKGc8JJwU0GeqYuUTja-vIca7p4PPr_i4/edit?usp=sharing">RasPi setup</a>)</p>
            <p>The frames holding it all together are printed from <a href="https://drive.google.com/drive/folders/1yhmFWAC9WZl5KNo4NMfis7nEZxAkWpuL?usp=sharing">these .STL files</a>(with paper as spacing to keep camera and accelerometer flat). I decided against implementing the project on real drones as I would have to make my own to avoid the high costs, they introduce many problems like pid tuning and make iterating take longer and more difficult. Plus, they wouldn’t add much to the project. </p>

            <h2>Results</h2>
            <p>Overall, the project seemed to work pretty well. Compared to other systems, it’s a bit slow and not the most accurate, and it also doesn’t have the greatest tolerance for orientation differences, but I still think it’s quite impressive for its simplicity and cost. </p>
            <p>In the future, it could be possible to find the 3d position of more features from any 2 drones so that the range is not limited to the central drone. The current system is also centralized, but it shouldn’t be too hard to fully decentralize it with stronger raspberry pi computers.</p>
        </div>
        <div class="footer">
            <p class="d-inline">Feel free to contact me about anything!</p>
            <a href="/about.html"><p class="d-inline">Contacts</p></a>
        </div>
    </div>


    <!-- Footer -->
    <footer>
        <div class="row fixed-bottom" id="page-footer">
            <div class="col-md-4 offset-md-4 text-center">
                
                <a href="/">© Matthew-Bird.com</a>
            </div>
            <div class="col-md-4 text-end">
                <p>Made by Matthew Bird</p>
            </div>
        </div>
    </footer>

    
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
</body>
</html>